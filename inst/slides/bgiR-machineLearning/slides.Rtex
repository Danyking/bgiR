\documentclass[UTF8]{beamer}
\usepackage{graphicx, color}
\usepackage{algorithm2e}
\usepackage{zhspacing}
\usepackage{amsmath}
\usepackage{tikz}
\usetikzlibrary{shapes,arrows}

% Define block styles
\tikzstyle{decision} = [diamond, draw, fill=blue!20, 
    text width=4.5em, text badly centered, node distance=3cm, inner sep=0pt]
\tikzstyle{block} = [rectangle, draw, fill=blue!20, 
    text width=5em, text centered, rounded corners, minimum height=3em]
\tikzstyle{line} = [draw, -latex']
\tikzstyle{cloud} = [draw, ellipse,fill=red!20, node distance=3cm,
    minimum height=2em]

\usepackage{underscore}
\usetheme{JuanLesPins}
\usepackage{fontspec}
\setsansfont{Microsoft YaHei}

\usepackage{enumerate}

\AtBeginSection[]{
	\frame{
		\frametitle{Next}
		\tableofcontents[currentsection, subsectionstyle=show/shaded/hide]
	}
}

\title{ML4Bioinfor-R}

\subtitle{Machine Learning for Bioinformatics using R\\}

\author{Gang Chen\\ chengang@bgitechsolutions.cn}


%% begin.rcode logo, echo=FALSE, results='asis'
%
% if(nchar(secLogo) > 0){
% cat(paste('\\logo{\\includegraphics[width=2cm]{bgi-logo.png}\\includegraphics[width=1cm]{',secLogo,'}}', sep=""))
% }else{
% cat('\\logo{\\includegraphics[width=2cm]{bgi-logo.png}}')
% }
%% end.rcode

%%begin.rcode subtitle, echo=FALSE, results='asis'
%
%  cat(paste('\\date{',subtitle, '\\\\ \\today}\n'));
% 
%
%%end.rcode


\begin{document}
\begin{frame}
\titlepage
\end{frame}
\begin{frame}[t]\frametitle{Outline}
\tableofcontents[hideallsubsections]
\end{frame}


\section{Introduction}

\begin{frame}[fragile]
  \frametitle{Identification of Biomarker}

%% begin.rcode, echo=F, out.height='.8\\textheight', out.width='.8\\textwidth', fig.align='center'
%
% library(bgiR)
%
% data(exprData)
%  
% labels = rep(c("normal","cancer"),53)
%
% layout(matrix(1:16, ncol=4, nrow=4))
%
% par = par()
%
% par(mar=c(2,2,2,2))
%
% tmp = sapply(1:16, function(x) boxplot(exprData[x,labels=="normal"],exprData[x,labels=="cancer"], names=c("normal","cancer"), main=rownames(exprData)[x], col=c("green","red")))
%
%% end.rcode
\end{frame}


\begin{frame}
  \includegraphics[height=.5\textheight]{escc.jpg}
  \includegraphics[height=.5\textheight]{esccNormal.jpg}\\

\centerline{How to identify tumor from genomics perspective?}

\centerline{\huge{The answer is Data Mining.}}
\end{frame}

\subsection{What is Data Mining?}

\begin{frame}
  \frametitle{What is Data Mining?}

  \begin{block}{Pang-Ning Tan, Introduction to Data Mining}
Data Mining is the process of automatically discovering useful information in large data repositories.
  \end{block}

  \begin{block}{Knowledge Discovery in Databases}
Data Mining is an integral part of knowledge discovery in databases(KDD).
  \end{block}
\end{frame}
\begin{frame}
  \frametitle{Data Mining and KDD}
\centerline{\includegraphics[width=\textwidth]{dmkdd.png}}
\end{frame}


\begin{frame}
  \frametitle{Data Mining and Bioinformatics}
\begin{columns}[c]
\begin{column}{.2\textwidth}
\small{Biological Experiments}\\
\tiny{Sequencing}\\
\tiny{Mass Spectrum}\\
\ldots
\end{column}
\begin{column}{.05\textwidth}
$\rightarrow$
\end{column}
\begin{column}{.2\textwidth}
\small{Preprocssing}\\
\tiny{base calling}\\
\tiny{alignment}\\
\tiny{variants}\\
\ldots
\end{column}
\begin{column}{.05\textwidth}
$\rightarrow$
\end{column}
\begin{column}{.25\textwidth}
Data Mining\\
\tiny{Classification}\\
\tiny{Regression}\\
\tiny{Feature Engineering}\\
\ldots
\end{column}

\begin{column}{.05\textwidth}
$\rightarrow$
\end{column}

\begin{column}{.2\textwidth}
Biological Knowledge
\end{column}
\end{columns}
\end{frame}


\begin{frame}
  \frametitle{Traditional Data Analysis}

  \begin{block}{Motivations}
\begin{itemize}
\item Scalability
\item High Dimensionality
\item Heterogeneous and Complex Data
\item Data Ownership and Distribution
\item Non-traditional analysis
\end{itemize}
  \end{block}
\end{frame}

\subsection{Data Mining Tasks}


\begin{frame}
  \frametitle{Data Mining Tasks}
\centerline{\includegraphics[height=.6\textheight]{dmtasks.jpg}}
\end{frame}

\subsection{Organization of the course}


\begin{frame}
  \frametitle{Schedule}

  \begin{block}{Schedule}
\begin{itemize}
\item Supervised Learning: Classifition (1 hr)
\item Unsupervised Learning: Clustering (1 hr)
\item Feature Learning: Selection and Extraction (1 hr)
\end{itemize}
  \end{block}
\end{frame}

\begin{frame}
  \frametitle{Softwares}
  \begin{block}{Softwares}
\begin{itemize}
\item R: R is an free platform for data analysis and visuaztion.
\item Rtools is required for Winodws systems.
\item R packages: 
\begin{itemize}
\item \textbf{e1071} for SVM
\item \textbf{fselector} for feature selection
\item \textbf{rpart} for decision tree
\item \textbf{bgiR} includes all necessary things\\
https://github.com/gangchen/bgiR
\end{itemize}
\item R IDE: Emacs + ESS, Vim + R-Plugin, RStudio or any other editor you like.
\item Operation Systems: Windows, Linux or Mac OS
\end{itemize}
  \end{block}
\end{frame}


\begin{frame}[fragile]
  \frametitle{Software}

  \begin{block}{bgiR package}
    bgiR package is an R package developed for R related training.\\
    Website: https://github.com/gangchen/bgiR
  \end{block}


%% begin.rcode, eval=FALSE
%
% install.packages("devtools")
% library(devtools)
% install_github("bgiR", "gangchen")
%
%% end.rcode

\end{frame}

\section{Supervised Learning}

\begin{frame}
\frametitle{Supervised Learning: Classification}

\begin{block}{Classification}
Assigning objects to one of several predefined categoriies.
\end{block}


\begin{block}{Definition}
Classification is the task of learning a \textbf{target function} $f$ that maps each attribute set $x$ to one of the predefined class labels $y$.
\end{block}
\end{frame}


\begin{frame}
  \frametitle{How to solve a classification problem?}
\begin{center}
\begin{tikzpicture}[node distance = 2cm, auto]
    % Place nodes
    \node [block] (model) {Model};
    \node [block, above left of=model, node distance=2.2cm] (lmodel) {Learn Model};
    \node [block, above of=lmodel, node distance=2cm] (lalg) {Learning Algorithm};
    \node [block, left of=lmodel, node distance=3cm] (train) {Training Set};
    \node [block, below left of=model, node distance=2.2cm] (amodel) {Apply Model};
    \node [block, left of=amodel, node distance=3cm] (test) {Testing Set};


    % Draw edges
    \path [line] (train) -- (lmodel);
    \path [line] (lalg) -- (lmodel);
    \path [line] (lmodel) -- (model);
    \path [line] (model) -- (amodel);
    \path [line] (amodel) -- (test);
\end{tikzpicture}\\
General approach for building a classification model
\end{center}
\end{frame}


\begin{frame}
  \frametitle{Evaluation}
\begin{center}
Confusion Matrix for a 2-class problem
  \begin{tabular}{|c|c|c|}
\hline
  & Prediction=1 & Prediction=0 \\
\hline
Class=1 & $f_{11}$ & $f_{10}$ \\
\hline
Class=0 & $f_{01}$ & $f_{00}$\\
\hline
  \end{tabular}
\end{center}
\end{frame}


\begin{frame}
  \frametitle{Evaluation}

  \begin{block}{Accuracy and Error Rate}

    \begin{align*}
      Accuracy & = \frac{\text{Number of correct predictions}}{\text{Total number of predictions}}\\
&=\frac{f_{11}+f_{00}}{f_{11}+f_{10}+f_{00}+f_{01}}\\
      Error Rate &= \frac{\text{Number of wrong predictions}}{\text{Total number of predictions}}\\
&=\frac{f_{10}+f_{01}}{f_{11}+f_{10}+f_{00}+f_{01}}
    \end{align*}
  \end{block}
\end{frame}

\subsection{Supervised Learning in Bioinformatics}


\begin{frame}
  \frametitle{Classification in Bioinformatics}

  \begin{block}{Applications}
\begin{itemize}
\item Classification of diseases, expecially cancer.
\item Prediction of clinical outcome.
\item Prediction of the function of gene or proteins.
\item Prediction of the structure of proteins.
\item \ldots \ldots
\end{itemize}
  \end{block}
\end{frame}


\begin{frame}
  \frametitle{Objective}
  \begin{block}{Two Objectives}
    \begin{enumerate}
      \item To build accuate classifiers or predictors
      \item To derive inferences from the results obtained
    \end{enumerate}
  \end{block}

  \begin{block}{Challanges}
    \begin{itemize}
      \item data incocnsistency and missing values
      \item noise
      \item normalization
      \item Deimensionality reduction
    \end{itemize}
  \end{block}
\end{frame}

\subsection{Decision Tree and its Applications in Bioinformatics}


\begin{frame}
  \frametitle{Decision Tree}
\centerline{\includegraphics[height=.7\textheight]{dt1.jpg}}
\end{frame}


\begin{frame}
  \frametitle{Concepts}
  \begin{block}{Types of Nodes}
    \begin{description}
      \item[root node]:no incoming edges and zero or more outgoing edges.
      \item[internal nodes]: has exactly one incoming edge and two or more outgoing edges.
      \item[leaf or terminal nodes]: has exactly one incoming edge and no outgoing edges.
    \end{description}
  \end{block}
\end{frame}


\begin{frame}
  \frametitle{How to build a Decision Tree?}
\footnotesize
  \begin{block}{Hunt's Algorithm}
Let $D_t$ be the set of training records that are associated with node $t$ and $y={y_1, y_2,\ldots, y_c}$ to be the class labels.
    \begin{enumerate}
      \item if all the records in $D_t$ belong to the same class $y_t$, then $t$ is a leaf node labeled as $y_i$.
      \item if $D_i$ contains records that belong to more than one class, an \textbf{attribute test condition} is selected to partition the records into smaller subsets. A child node is created for each outcome of the test condition and the records in $D_t$ are distributed to the chirldren based on the outcomes. The algorithm is then recursively applied to each child node.
    \end{enumerate}
  \end{block}
\end{frame}


\begin{frame}
\footnotesize
\textbf{Algorithm} A skeleton decision tree induction algorithm\\
\textbf{TreeGrowth$(E,F)$}

\begin{algorithm}[H]
\SetAlgoLined
  \eIf{stopping_cond($E, F$) = $true$}{
       $leaf = createNode()$\;
       $leaf.label = Classify(E)$\;
       \Return{return $leaf$}
}{
       $root$ = createNode()\;
       $roor.test\_cond$ = find_best_split($E, F$)\;
       let $V = {v|v \text{is a possible outcome of }root.test\_cond}$
       \For{each $v \in V$ do}{
           $E_v = {e | root.test\_cond(e)=v \text{and} e \in E}$\;
           $child = TreeGrowth(E_v, F)$\;
           add $child$ as descendent of $root$ and label the edge ($root \rightarrow child$) as $v$}
  }
  \Return{root}
\end{algorithm}

\end{frame}


\begin{frame}[fragile]
  \frametitle{Decision Tree in R}

%% begin.rcode, eval=FALSE
% library(rpart)
% library(C50)
% library(party)
%% end.rcode
\end{frame}


\begin{frame}[fragile]
  \frametitle{C5.0 Algorithm in R}

%% begin.rcode, eval=FALSE
%
% library(C50)
% C5.0(x, y)
% # x is a data frame or a matrix of records
%
% # y is a factor vector of class lables
%
%% end.rcode
\end{frame}


\begin{frame}[fragile]
  \frametitle{Decision Tree on Gene Expression Data}

%% begin.rcode
%
%# load BGI package for R training
% library(bgiR) 
% library(C50) # load C50 package
%# load ESCC microarray data of 1000 probesets
% data(exprData) 
% dt = C5.0(t(exprData), as.factor(rep(0:1,53)))
%
%% end.rcode
\end{frame}


\begin{frame}[fragile]
\tiny
%% begin.rcode
%
% summary(dt)
%
%% end.rcode
\end{frame}

\subsection{Support Vector Machine and its Applications in Bioinformatics}


\begin{frame}
  \frametitle{SVM}
\centerline{\includegraphics[height=.7\textheight]{svm.png}}
\end{frame}

\begin{frame}
  \frametitle{Kernal}
\centerline{\includegraphics[height=.7\textheight]{kernel.jpg}}
\end{frame}


\begin{frame}
  \frametitle{SVM in R}


%% begin.rcode, eval=FALSE
%
% library(e1071)
%
%% end.rcode

\end{frame}

\subsection{Other Classification Techniques}

\section{Unspervised Learning}

\subsection{Unspervised Learning in Bioinformatics}

\subsection{K-means Clustering and its Applications in Bioinformatics}


\begin{frame}
  \frametitle{K-means}

%% begin.rcode, eval=FALSE
%
% help(kmeans)
%
%% end.rcode
\end{frame}

\subsection{Hierarchical Clustering and its Applications in Bioinformatics}


\begin{frame}
  \frametitle{Hierarchical Clustering}

%% begin.rcode, eval=FALSE
%
% help(hclust)
%
% help(heatmap)
%
%% end.rcode
\end{frame}


\subsection{Other Clustering Techniques}

\section{Feature Learning}

\subsection{Feature Learning and Biomarker Identification}

\subsection{Feature Selection: Filter and Wrapper}

\begin{frame}
  \frametitle{Feature Selection}

%% begin.rcode, eval=FALSE
%
% library(FSelector)
%
%% end.rcode
\end{frame}


\subsection{REILEF method}

\subsection{Feature Extraction}

\subsection{Principal Component Analysis}


\begin{frame}
  \frametitle{PCA}

%% begin.rcode, eval=FALSE
%
% help(princomp)
%
% help(prcomp)
%
%% end.rcode
\end{frame}


\subsection{Other Feature Learning Techniques}

\section{Future}


\begin{frame}
  \frametitle{Future Reading}
\begin{itemize}
\item Data Mining for Bioinformatics
\item Introduction to Machine Learning
\item CRAN Task View: Machine Learning \& Statistical Learning: http://cran.r-project.org/web/views/MachineLearning.html
\end{itemize}
\end{frame}


\begin{frame}
  \centerline{\Huge{Thanks!}}
\end{frame}

\end{document}